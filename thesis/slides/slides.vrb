\frametitle{\texttt {VegasFlow}}
\scriptsize
\texttt{VegasFlow}: implementation of the Vegas importance sampling using hardware acceleration.

This is possible thanks to the \texttt{TensorFlow} library which enable us to distribute python code to hardware acceleration devices.
		\begin{columns}
		\begin{column}{0.5 \textwidth}
			\tiny
			Better computational times for physical integrand!
			\vspace{-0.3cm}
			\begin{figure}
				\includegraphics[ width = \columnwidth]{../tex/images/vf_singletop.png}
				
				\vspace{-0.2cm}
					\caption{Comparison of a Leading Order calculation ran in both \texttt{VegasFlow}
					 and MG5\_aMC@NLO . For the same level
					of target accuracy \texttt{VegasFlow} is faster than  MG5\_aMC@NLO when using both CPUs and GPUs devices. }

				
				
			\end{figure}
		\end{column}
		\begin{column}{0.5 \textwidth}
			\begin{figure}
				\vspace{-0.6cm}
				\tiny
				Advantage of graph implementation!
				
				\includegraphics[ width = \columnwidth]{../tex/images/graph_mode.png}
				
								\vspace{-0.3cm}
				\caption{Comparison of performance between the eager and graph compilation TensorFlow mode. The results are shown as a ratio of the time it took the eager computation to complete one iteration.}
			\end{figure}
		\end{column}
		
	\end{columns}

Our aim is to implement the \texttt{VEGAS+} algorithm within the \texttt{VegasFlow} library, empowering the algorithm by enabling to run the integration in GPUs.




	
